{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, dayofweek, minute, second\n",
    "from pyspark.sql.functions import split\n",
    "    \n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, StringType, TimestampType\n",
    "from pyspark.sql.functions import col,when, coalesce\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dl.cfg']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AKIAZD4WPUXSZK3QIHPE'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID']=config['KEYS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_ACCESS_KEY_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wdKM7tHrC+9PL0fgEXmUowcpOvqStHNUKJnYqkh4'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['KEYS']['AWS_SECRET_ACCESS_KEY']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://e-commerce-sellout/nov/ s3a://e-commerce-sellout/nov/\n"
     ]
    }
   ],
   "source": [
    "s3Url = config['KEYS']['AWS_S3_ENDPOINT']\n",
    "writePath = s3Url\n",
    "\n",
    "print(s3Url, writePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv parquet\n"
     ]
    }
   ],
   "source": [
    "csvFormat = config['KEYS']['CSV_FORMAT']\n",
    "parquetFormat = config['KEYS']['PARQUET_FORAMT']\n",
    "\n",
    "print(csvFormat , parquetFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "targetField = config['KEYS']['TAGET_FILED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenovo\n"
     ]
    }
   ],
   "source": [
    "targetBrand = config['KEYS']['TAGET_BRAND']\n",
    "targetBrand = 'lenovo'\n",
    "\n",
    "print(targetBrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "product = config['KEYS']['PRODUCT_TABLE']\n",
    "event = config['KEYS']['EVENT_TABLE']\n",
    "user = config['KEYS']['USER_TABLE']\n",
    "count = config['KEYS']['VALID_COUNT']\n",
    "summary = config['KEYS']['SUMMARY']\n",
    "# count\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://e-commerce-sellout/nov/product'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productPath = writePath+product\n",
    "productPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# temp = []\n",
    "\n",
    "# a= {product:'product'} \n",
    "# b= {event:'event'}\n",
    "# c= {event:'user'}\n",
    "\n",
    "# temp.append(a)\n",
    "# temp.append(b)\n",
    "# temp.append(c)\n",
    "\n",
    "# temp[0]['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dataList = []\n",
    "# dataList.append(product)\n",
    "# dataList.append(event)\n",
    "# dataList.append(user)\n",
    "# dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for data in dataList:\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://e-commerce-sellout/nov/'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3EndPoint = config['KEYS']['AWS_S3_ENDPOINT']\n",
    "s3EndPoint\n",
    "\n",
    "# s3writePath = config['KEYS']['AWS_S3_WRITE_PATH_TEST']\n",
    "# parquetPath = s3writePath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sparkSession():\n",
    "    spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .config('spark.jars.packages','org.apache.hadoop:hadoop-aws:2.7.0')\\\n",
    "            .getOrCreate()\n",
    "    print(spark)\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fe396e592e8>\n",
      "<pyspark.sql.session.SparkSession object at 0x7fe396e592e8>\n"
     ]
    }
   ],
   "source": [
    "spark = sparkSession()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def filterTargetData(dataFrame, field, name):\n",
    "    \"\"\"\n",
    "    function: filter dataframe\n",
    "    @params\n",
    "    dataframe: spark dataFrame\n",
    "    field: target field to filter dataframe\n",
    "    name: value to filter data\n",
    "    \"\"\"\n",
    "    print(dataFrame, field, name)\n",
    "    return dataFrame.filter( col(field) == name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loadData(spark, formatType ,path):\n",
    "    \"\"\"\n",
    "    function : read data from the selected storage\n",
    "    @params \n",
    "    spark: sparkSession\n",
    "    path: the selected storage\n",
    "    \"\"\" \n",
    "    print(spark, formatType, path)\n",
    "    return spark.read.format(formatType)\\\n",
    "                        .option(\"header\", 'true')\\\n",
    "                        .load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fe396e592e8> csv s3a://e-commerce-sellout/nov/\n"
     ]
    }
   ],
   "source": [
    "#print(spark, csvFormat, s3Url) \n",
    "mainData = loadData(spark, csvFormat, s3Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[event_time: string, event_type: string, product_id: string, category_id: string, category_code: string, brand: string, price: string, user_id: string, user_session: string] brand lenovo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "targetBrand\n",
    "\n",
    "#process.filterTargetData(mainData, field ,targetBrand)\n",
    "rawData = filterTargetData(mainData, targetField ,targetBrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_time: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- category_id: string (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_session: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " mainData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def processProductData(dataFrame):\n",
    "    \"\"\"\n",
    "    Function : process product data to return unique data in selected dataframe\n",
    "    @params \n",
    "    dataframe: spark dataframe\n",
    "    \"\"\"\n",
    "    return dataFrame.select('product_id','category_id','category_code','brand','price').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------------+------+------+\n",
      "|product_id|        category_id|       category_code| brand| price|\n",
      "+----------+-------------------+--------------------+------+------+\n",
      "|   1701416|2053013553031414015|computers.periphe...|lenovo|107.31|\n",
      "+----------+-------------------+--------------------+------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#productData = process.processProductData(rawData)\n",
    "productData = processProductData(rawData)\n",
    "productData.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def processEventData(dataFrame): \n",
    "    \"\"\"\n",
    "    Function : process event data to return unique data in selected dataframe\n",
    "    @params \n",
    "    dataframe: spark dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    return dataFrame.select('event_time','event_type','product_id','user_session').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#eventData = process.processEventData(rawData)\n",
    "eventData = processEventData(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def processUserData(dataFrame):\n",
    "    \"\"\"\n",
    "    Function : process user data to return unique data in selected dataframe\n",
    "    @params \n",
    "    dataframe: spark dataframe\n",
    "    \"\"\" \n",
    "    \n",
    "    return dataFrame.select('user_session','user_id').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#userData = process.processUserData(rawData)\n",
    "userData = processUserData(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def writeData(dataFrame, isPartitioned, partition, outputPath):\n",
    "    print(isPartitioned, partition, outputPath)\n",
    "    \"\"\"\n",
    "    Function : write data to the selected storage\n",
    "    @params \n",
    "    dataframe: spark dataframe\n",
    "    isPartitioned: boolean type. enable to partiton or not\n",
    "    outputPath: storage where data take places\n",
    "    key: folder name    \n",
    "    \"\"\" \n",
    "    if(isPartitioned):\n",
    "        print('Partitioned')\n",
    "        return dataFrame.write.partitionBy(partition).parquet(outputPath, mode='overwrite')\n",
    "    else:\n",
    "        print('Non-Partitioned')\n",
    "        return dataFrame.write.parquet(outputPath, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def validateData(data, count):\n",
    "    \"\"\"\n",
    "    To run quailty check fucntion\n",
    "    @params\n",
    "    data: the list of dataframe\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print('No data')\n",
    "        return\n",
    "    else:\n",
    "        for df in data:\n",
    "            print('T data')\n",
    "            quality_checks(df, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def quality_checks(dataframe, count):\n",
    "    \"\"\"\n",
    "    To check dimension tables to make sure tables completes normally.\n",
    "    @params\n",
    "    :dataframe: spark dataframe\n",
    "    :tableName: table name\n",
    "    \"\"\"\n",
    "    total_count = df.count()\n",
    "    table_name = \"Target Table\"\n",
    "    if total_count == count:\n",
    "        print(f\"Data quality : {table_name} with zero records!\")\n",
    "    else:\n",
    "        print(f\"Data quality : {table_name} with {total_count} records.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data\n"
     ]
    }
   ],
   "source": [
    "# Data Qualtiy Check\n",
    "#     process.validateData(summary, count)\n",
    "temp = []\n",
    "validateData(temp, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True brand s3a://e-commerce-sellout/debug-test/product\n",
      "Partitioned\n"
     ]
    }
   ],
   "source": [
    "productPath = writePath+product\n",
    "productPath\n",
    "\n",
    "#process.wrtieData(productData, True, 'brand', productPath)\n",
    "writeData(productData, True, 'brand', productPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://e-commerce-sellout/debug-test/product'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productPath = writePath+product\n",
    "productPath\n",
    "\n",
    "#process.wrtieData(productData, False, '', eventPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://e-commerce-sellout/debug-test/user'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userPath = writePath+user\n",
    "userPath\n",
    "\n",
    "#process.writeData(productData, False, '', s3Url, user)\n",
    "writeData(productData, False, '', s3Url, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# formatType = 'json'\n",
    "# path='s3a://e-commerce-sellout/debug-test/'\n",
    "\n",
    "def loadParquetData(spark, formatType, path):\n",
    "    print(formatType, path)\n",
    "    \n",
    "    \"\"\"\n",
    "    Function : read data from the selected storage\n",
    "    @params \n",
    "    spark: sparkSession\n",
    "    path: the selected storage\n",
    "    \"\"\" \n",
    "    return spark.read.format('parquet')\\\n",
    "                .load(os.path.join(path,\"*/*/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://e-commerce-sellout/debug-test/*/*/'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pqPath = os.path.join(s3writePath, '*/*/'  )\n",
    "pqPath\n",
    "#loadData(spark, parquetFormat, pqPath).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def transformProductData(dataFrame):\n",
    "    \"\"\"\n",
    "    transformation : Split category fields by 'category_code'\n",
    "    action1) create new fields : category_major , category_middle, category_micro respectively\n",
    "    action2) fill micro category if category code is 2 words code only\n",
    "    \"\"\"\n",
    "\n",
    "    ## Insert default values into null category \n",
    "    fillCategory = dataFrame.fillna({'brand':'none','category_code':'category1.category2.category3'})\n",
    "    \n",
    "    splitCategory = fillCategory.withColumn(\"category_major\",  split(col(\"category_code\"),'\\.').getItem(0))\\\n",
    "                                .withColumn(\"category_middle\", split(col(\"category_code\"),'\\.').getItem(1))\\\n",
    "                                .withColumn(\"category_micro\",  split(col(\"category_code\"),'\\.').getItem(2))\\\n",
    "                                .withColumn('category_micro',  coalesce(  \"category_micro\",  \"category_middle\" ))\\\n",
    "                                .withColumn(\"price\", col(\"price\").cast(DoubleType())  )\\\n",
    "                                .select('brand',\n",
    "                                        'category_major', 'category_middle','category_micro'\n",
    "                                        ,'category_id','product_id','price')\n",
    "    return splitCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------+--------------+-------------------+----------+-------+\n",
      "| brand|category_major|category_middle|category_micro|        category_id|product_id|  price|\n",
      "+------+--------------+---------------+--------------+-------------------+----------+-------+\n",
      "|lenovo|     computers|    peripherals|       monitor|2053013553031414015|   1701416| 107.31|\n",
      "|lenovo|     computers|       notebook|          null|2053013558920217191|   1307091|1902.69|\n",
      "|lenovo|     category1|      category2|     category3|2053013558525952589|  18001082|   2.32|\n",
      "|lenovo|     computers|       notebook|          null|2053013558920217191|   1306821| 1147.6|\n",
      "|lenovo|     computers|     components|        memory|2053013554189041997| 100008036| 157.88|\n",
      "|lenovo|     computers|       notebook|          null|2053013558920217191|   1306678|1200.89|\n",
      "|lenovo|     computers|    peripherals|       monitor|2053013553031414015|   1701570| 115.19|\n",
      "|lenovo|   electronics|         tablet|          null|2172371436436455782|   1201192| 177.84|\n",
      "|lenovo|     computers|       notebook|          null|2053013558920217191| 100006123|1008.03|\n",
      "|lenovo|     computers|       notebook|          null|2053013558920217191|   1307004|  352.0|\n",
      "|lenovo|     computers|        desktop|          null|2053013561092866779|   1480737| 759.91|\n",
      "|lenovo|     computers|       notebook|          null|2053013558920217191|   1307362| 720.56|\n",
      "|lenovo|   accessories|            bag|          null|2053013558945383017|  18300959|   49.9|\n",
      "|lenovo|     computers|     components|           hdd|2053013554222596431|   6801417| 514.79|\n",
      "|lenovo|     computers|        desktop|          null|2053013561092866779|   1480762|1775.03|\n",
      "|lenovo|     computers|       notebook|          null|2053013558920217191|   1306822| 851.99|\n",
      "|lenovo|     computers|        desktop|          null|2053013561092866779|   1480405|1139.88|\n",
      "|lenovo|     computers|       notebook|          null|2053013558920217191|   1307528|1080.34|\n",
      "|lenovo|     computers|        desktop|          null|2053013561092866779|   1480405|1139.86|\n",
      "|lenovo|     computers|    peripherals|       monitor|2053013553031414015|   1701578| 580.45|\n",
      "+------+--------------+---------------+--------------+-------------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category = transformProductData(productData)\n",
    "category.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def transformEventData(dataFrame):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "     \n",
    "    # Create time table\n",
    "    ## transformation : Split time stamps\n",
    "    ## action1) create new fields : year, month, day\n",
    "\n",
    "    eventTime = eventData.withColumn(\"yyyyMmDd\", split(col(\"event_time\"),' ').getItem(0))\\\n",
    "                        .withColumn(\"year\", year(\"yyyyMmDd\"))\\\n",
    "                        .withColumn(\"month\", month(\"yyyyMmDd\"))\\\n",
    "                        .withColumn(\"day\", dayofmonth(\"yyyyMmDd\"))\\\n",
    "                        .select('event_time', 'year', 'month','day'\n",
    "                                ,'event_type','product_id','user_session')\n",
    "\n",
    "    return eventTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----+---+----------+----------+--------------------+\n",
      "|          event_time|year|month|day|event_type|product_id|        user_session|\n",
      "+--------------------+----+-----+---+----------+----------+--------------------+\n",
      "|2019-11-01 01:39:...|2019|   11|  1|      view|   1307521|4a37da05-677f-4fc...|\n",
      "|2019-11-01 03:42:...|2019|   11|  1|      view|   1306544|c5c6a6b4-0bab-4c7...|\n",
      "|2019-11-01 03:42:...|2019|   11|  1|      view|   1306544|a064a17b-2d7c-420...|\n",
      "|2019-11-01 03:57:...|2019|   11|  1|      view|   1307044|0cae430f-e69e-47b...|\n",
      "|2019-11-01 04:20:...|2019|   11|  1|      view|   1480240|5bdec46f-e26f-4ce...|\n",
      "|2019-11-01 04:27:...|2019|   11|  1|      view|   1307067|6a86cca2-8d11-44f...|\n",
      "|2019-11-01 05:35:...|2019|   11|  1|      view|   1307478|2bcc2a58-3111-476...|\n",
      "|2019-11-01 05:35:...|2019|   11|  1|      view|   1307457|52d764f5-4270-45d...|\n",
      "|2019-11-01 05:40:...|2019|   11|  1|      view|   1307545|8fecca37-da32-451...|\n",
      "|2019-11-01 05:56:...|2019|   11|  1|      view|   1306467|52d764f5-4270-45d...|\n",
      "|2019-11-01 06:35:...|2019|   11|  1|      view|   1306437|68c84f7a-20b9-4b4...|\n",
      "|2019-11-01 06:42:...|2019|   11|  1|      view|   1307179|e65f0cb5-6e7f-42a...|\n",
      "|2019-11-01 06:56:...|2019|   11|  1|      view|   1307237|13a07ef1-ed01-48b...|\n",
      "|2019-11-01 06:58:...|2019|   11|  1|      view|   1480371|dcdeb449-30ab-42b...|\n",
      "|2019-11-01 07:07:...|2019|   11|  1|      view|   1307044|b412bbba-93be-41f...|\n",
      "|2019-11-01 07:42:...|2019|   11|  1|      view|   1307067|30103fd1-e1d0-474...|\n",
      "|2019-11-01 07:53:...|2019|   11|  1|      view|   1307179|1c2dc77e-f3e7-4df...|\n",
      "|2019-11-01 07:58:...|2019|   11|  1|      view|   1201579|16530568-44e7-4df...|\n",
      "|2019-11-01 08:08:...|2019|   11|  1|      view|   1307153|465106be-6efd-478...|\n",
      "|2019-11-01 08:25:...|2019|   11|  1|      view|   1307478|e325dcfa-d31e-4c1...|\n",
      "+--------------------+----+-----+---+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eventTime = transformEventData(eventData)\n",
    "eventTime.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def summaryTargetData(mainData, subData):\n",
    "    \"\"\"\n",
    "    \"\"\" \n",
    "    joinData = mainData.alias(\"M\").join(subData.alias(\"S\"), mainData.product_id == subData.product_id , how='inner')\n",
    "    \n",
    "    return joinData.groupBy('day','event_type','category_micro')\\\n",
    "                    .sum('price')\\\n",
    "                    .agg(sum(\"price\").alias(\"total_sum\"))\\\n",
    "                    .select('year','month','day','event_type',\n",
    "                            'category_mmajor','category_middle','category_micro',\n",
    "                            'total_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brand',\n",
       " 'category_major',\n",
       " 'category_middle',\n",
       " 'category_micro',\n",
       " 'category_id',\n",
       " 'product_id',\n",
       " 'price',\n",
       " 'event_time',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'event_type',\n",
       " 'product_id',\n",
       " 'user_session']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinData = category.alias(\"M\").join(eventTime.alias(\"S\"), category.product_id == eventTime.product_id , how='inner')\n",
    "joinData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------+--------------------+\n",
      "|day|event_type|category_micro|          sum(price)|\n",
      "+---+----------+--------------+--------------------+\n",
      "| 23|      cart|      keyboard|   975.6000000000001|\n",
      "| 13|      cart|      keyboard|              583.48|\n",
      "| 10|      view|        memory|              311.14|\n",
      "| 27|  purchase|          null|           344148.47|\n",
      "| 14|      view|       monitor|   87621.34999999999|\n",
      "| 23|      cart|          null|    733601.759999999|\n",
      "| 23|      view|           hdd|            22847.32|\n",
      "|  4|      view|           hdd|  12897.919999999998|\n",
      "|  5|      view|          null|3.7119080569999814E7|\n",
      "| 29|      view|      keyboard|             9054.58|\n",
      "|  5|      view|       monitor|   38956.20999999999|\n",
      "| 21|      cart|         mouse|              132.68|\n",
      "| 10|      view|      keyboard|  14415.109999999997|\n",
      "| 28|      view|      keyboard|  4506.0700000000015|\n",
      "| 18|  purchase|         mouse|                83.1|\n",
      "| 18|      view|     headphone|  2607.0399999999995|\n",
      "| 14|      cart|     headphone|              423.96|\n",
      "| 20|      cart|         mouse|  115.11999999999999|\n",
      "| 23|      view|        memory|             3448.38|\n",
      "| 17|      cart|     headphone|              423.96|\n",
      "+---+----------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinData.groupBy('day','event_type','category_micro')\\\n",
    "                    .sum('M.price')\\\n",
    "                    .alias(\"total_sum\").show()\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#summaryTargetData(category, eventTime).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def quality_checks(dataframe):\n",
    "    \"\"\"\n",
    "    To check dimension tables to make sure tables completes normally.\n",
    "    @params\n",
    "    :dataframe: spark dataframe\n",
    "    :tableName: table name\n",
    "    \"\"\"\n",
    "    total_count = df.count()\n",
    "    table_name = \"Target Table\"\n",
    "    if total_count == 0:\n",
    "        print(f\"Data quality : {table_name} with zero records!\")\n",
    "    else:\n",
    "        print(f\"Data quality : {table_name} with {total_count} records.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(spark, csvFormat, s3Url, writePath , csvFormat, parquetFormat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
